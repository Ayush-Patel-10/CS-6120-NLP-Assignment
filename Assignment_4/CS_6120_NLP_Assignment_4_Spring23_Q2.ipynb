{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e479cede",
   "metadata": {
    "id": "b0711aee",
    "papermill": {
     "duration": 0.007902,
     "end_time": "2023-03-28T00:00:22.780384",
     "exception": false,
     "start_time": "2023-03-28T00:00:22.772482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a name='2'></a>\n",
    "# Part 2: LSTMs for POS tagging - using PyTorch (40 Points)\n",
    "In this part, We will be building a bidirectional LSTM network to train and inference POS tagging on UDPOS dataset.<br>\n",
    "\n",
    "PyTorch makes it easy by abstracting most of the details that go in building,training and inferencing a neural network. We recommend going through every PyTorch function that this notebook uses to gain more understanding.   \n",
    "\n",
    "If you need a refresher or have never worked with Neural Networks before, here are a few resources:\n",
    "- https://web.stanford.edu/~jurafsky/slp3/7.pdf\n",
    "- https://web.stanford.edu/~jurafsky/slp3/9.pdf\n",
    "- https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "We will be using PyTorch for defining, training and inferencing a neural network for our POS Tagging problem. If you have not used any deep learning framework/library, we recommend you spend some time understanding how to use these libraries. \n",
    "\n",
    "PyTorch Resources:\n",
    "- https://pytorch.org/tutorials/\n",
    "- https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e87c63",
   "metadata": {
    "id": "58b4818c",
    "papermill": {
     "duration": 0.006354,
     "end_time": "2023-03-28T00:00:22.793565",
     "exception": false,
     "start_time": "2023-03-28T00:00:22.787211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You will need the following imports. Install these libraries using the following commands. \n",
    "- Installing pytorch - https://pytorch.org/get-started/locally/ (choose your setup from here)\n",
    "- conda install -c conda-forge spacy\n",
    "- conda install -c pytorch torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8482f59",
   "metadata": {
    "id": "06f6b3a6",
    "papermill": {
     "duration": 0.006317,
     "end_time": "2023-03-28T00:00:22.806481",
     "exception": false,
     "start_time": "2023-03-28T00:00:22.800164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training a neural network model will take time. \n",
    "- Make use of your **Nvidia** GPU if you have one. \n",
    "- If not, you can use Google Colab / Kaggle notebooks. You get a free GPU for a limited time to tweak your hyperparameters.\n",
    "- Without a GPU, You might have to wait longer to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c96e1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:00:22.822160Z",
     "iopub.status.busy": "2023-03-28T00:00:22.821676Z",
     "iopub.status.idle": "2023-03-28T00:01:40.579965Z",
     "shell.execute_reply": "2023-03-28T00:01:40.578730Z"
    },
    "id": "YZ9wEpbZN9E7",
    "outputId": "fbc449d1-a63e-4936-cf8f-115cc390455d",
    "papermill": {
     "duration": 77.769604,
     "end_time": "2023-03-28T00:01:40.582706",
     "exception": false,
     "start_time": "2023-03-28T00:00:22.813102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.8.0\r\n",
      "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.5/735.5 MB\u001b[0m \u001b[31m994.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.8.0) (1.21.6)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.8.0) (4.4.0)\r\n",
      "Installing collected packages: torch\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.13.0\r\n",
      "    Uninstalling torch-1.13.0:\r\n",
      "      Successfully uninstalled torch-1.13.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torchmetrics 0.11.1 requires torch>=1.8.1, but you have torch 1.8.0 which is incompatible.\r\n",
      "pytorch-lightning 1.9.3 requires torch>=1.10.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.8.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting torchtext==0.9.0\r\n",
      "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch==1.8.0 in /opt/conda/lib/python3.7/site-packages (from torchtext==0.9.0) (1.8.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtext==0.9.0) (1.21.6)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.9.0) (4.64.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext==0.9.0) (2.28.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.8.0->torchtext==0.9.0) (4.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (2.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (2022.12.7)\r\n",
      "Installing collected packages: torchtext\r\n",
      "  Attempting uninstall: torchtext\r\n",
      "    Found existing installation: torchtext 0.14.0\r\n",
      "    Uninstalling torchtext-0.14.0:\r\n",
      "      Successfully uninstalled torchtext-0.14.0\r\n",
      "Successfully installed torchtext-0.9.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.8.0\n",
    "!pip install torchtext==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459a4093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:01:40.627298Z",
     "iopub.status.busy": "2023-03-28T00:01:40.626970Z",
     "iopub.status.idle": "2023-03-28T00:02:02.858277Z",
     "shell.execute_reply": "2023-03-28T00:02:02.857155Z"
    },
    "id": "afef2ff0",
    "papermill": {
     "duration": 22.256933,
     "end_time": "2023-03-28T00:02:02.861223",
     "exception": false,
     "start_time": "2023-03-28T00:01:40.604290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# a package that provides processing utilities and popular datasets for natural language\n",
    "\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy.datasets import UDPOS\n",
    "\n",
    "import spacy\n",
    "from tqdm import tqdm \n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d900a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:02:02.906582Z",
     "iopub.status.busy": "2023-03-28T00:02:02.905927Z",
     "iopub.status.idle": "2023-03-28T00:02:02.913346Z",
     "shell.execute_reply": "2023-03-28T00:02:02.912415Z"
    },
    "id": "878101a3",
    "papermill": {
     "duration": 0.031971,
     "end_time": "2023-03-28T00:02:02.915549",
     "exception": false,
     "start_time": "2023-03-28T00:02:02.883578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using a seed to maintain consistent and reproducible results\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160edccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:02:02.958979Z",
     "iopub.status.busy": "2023-03-28T00:02:02.958676Z",
     "iopub.status.idle": "2023-03-28T00:02:04.914397Z",
     "shell.execute_reply": "2023-03-28T00:02:04.913365Z"
    },
    "id": "7f8ba127",
    "outputId": "1c74a3d6-0975-4111-d0b4-f2eb15713913",
    "papermill": {
     "duration": 1.980176,
     "end_time": "2023-03-28T00:02:04.916847",
     "exception": false,
     "start_time": "2023-03-28T00:02:02.936671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading en-ud-v2.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "en-ud-v2.zip: 100%|██████████| 688k/688k [00:00<00:00, 2.27MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting\n"
     ]
    }
   ],
   "source": [
    "# This cell downloads and prepares data, a TorchText Dataset Object\n",
    "\n",
    "TEXT = data.Field(lower = True)\n",
    "UD_TAGS = data.Field(unk_token = None)\n",
    "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS))\n",
    "train_data, valid_data, test_data = UDPOS.splits(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08c2b4",
   "metadata": {
    "id": "1717eb2b",
    "papermill": {
     "duration": 0.021937,
     "end_time": "2023-03-28T00:02:04.960931",
     "exception": false,
     "start_time": "2023-03-28T00:02:04.938994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualizing the torchtext dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c11a0887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:02:05.005638Z",
     "iopub.status.busy": "2023-03-28T00:02:05.005248Z",
     "iopub.status.idle": "2023-03-28T00:02:05.012932Z",
     "shell.execute_reply": "2023-03-28T00:02:05.011906Z"
    },
    "id": "069d103b",
    "outputId": "a989d56c-b6c4-4920-a03f-b6d85ceeb758",
    "papermill": {
     "duration": 0.033365,
     "end_time": "2023-03-28T00:02:05.015882",
     "exception": false,
     "start_time": "2023-03-28T00:02:04.982517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset 12543\n",
      "TEXT  1 al - zaman : american forces killed shaikh abdullah al - ani , the preacher at the mosque in the town of qaim , near the syrian border .\n",
      "TAGS  1 PROPN PUNCT PROPN PUNCT ADJ NOUN VERB PROPN PROPN PROPN PUNCT PROPN PUNCT DET NOUN ADP DET NOUN ADP DET NOUN ADP PROPN PUNCT ADP DET ADJ NOUN PUNCT\n",
      "TEXT  2 [ this killing of a respected cleric will be causing us trouble for years to come . ]\n",
      "TAGS  2 PUNCT DET NOUN ADP DET ADJ NOUN AUX AUX VERB PRON NOUN ADP NOUN PART VERB PUNCT PUNCT\n",
      "TEXT  3 dpa : iraqi authorities announced that they had busted up 3 terrorist cells operating in baghdad .\n",
      "TAGS  3 PROPN PUNCT ADJ NOUN VERB SCONJ PRON AUX VERB ADP NUM ADJ NOUN VERB ADP PROPN PUNCT\n",
      "TEXT  4 two of them were being run by 2 officials of the ministry of the interior !\n",
      "TAGS  4 NUM ADP PRON AUX AUX VERB ADP NUM NOUN ADP DET PROPN ADP DET PROPN PUNCT\n",
      "TEXT  5 the moi in iraq is equivalent to the us fbi , so this would be like having j. edgar hoover unwittingly employ at a high level members of the weathermen bombers back in the 1960s .\n",
      "TAGS  5 DET PROPN ADP PROPN AUX ADJ ADP DET PROPN PROPN PUNCT ADV PRON AUX VERB SCONJ VERB PROPN PROPN PROPN ADV VERB ADP DET ADJ NOUN NOUN ADP DET PROPN NOUN ADV ADP DET NOUN PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the dataset\", len(train_data))\n",
    "for i in range(0,5):\n",
    "    print(\"TEXT \", i+1 ,*(train_data[i].__dict__['text']))\n",
    "    print(\"TAGS \", i+1 ,*(train_data[i].__dict__['udtags']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609dbd8",
   "metadata": {
    "id": "66b17bc2",
    "papermill": {
     "duration": 0.021355,
     "end_time": "2023-03-28T00:02:05.059681",
     "exception": false,
     "start_time": "2023-03-28T00:02:05.038326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### GloVe Vector initialization \n",
    "Vectorizing the input words is an impotant step in the NLP pipeline that can determine the end performance of neural networks. GloVe vectors capture both global statistics and local statistics of a corpus. We use GloVe to convert words to embeddings in the vector space based on their semantics. \n",
    "\n",
    "To learn more about GloVe please read the following resource:\n",
    "- https://nlp.stanford.edu/pubs/glove.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb0adee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:02:05.104454Z",
     "iopub.status.busy": "2023-03-28T00:02:05.104109Z",
     "iopub.status.idle": "2023-03-28T00:05:18.870667Z",
     "shell.execute_reply": "2023-03-28T00:05:18.869590Z"
    },
    "id": "f1a0c49b",
    "outputId": "743388e7-ffb2-4e47-bea3-0a777ddf620a",
    "papermill": {
     "duration": 193.791764,
     "end_time": "2023-03-28T00:05:18.873113",
     "exception": false,
     "start_time": "2023-03-28T00:02:05.081349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n",
      "100%|█████████▉| 399999/400000 [00:15<00:00, 25958.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# the words should have atleast a min frequency of 2 to build its vocab\n",
    "MIN_FREQ = 2\n",
    "\n",
    "# Torch text builds the vocabulary based on word representations from glove. \n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ,\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "UD_TAGS.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3298f6a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:05:19.097230Z",
     "iopub.status.busy": "2023-03-28T00:05:19.096875Z",
     "iopub.status.idle": "2023-03-28T00:05:19.104037Z",
     "shell.execute_reply": "2023-03-28T00:05:19.103042Z"
    },
    "id": "b15e4865",
    "outputId": "da5943bd-cc05-40ce-cbef-18e34885b312",
    "papermill": {
     "duration": 0.117972,
     "end_time": "2023-03-28T00:05:19.106039",
     "exception": false,
     "start_time": "2023-03-28T00:05:18.988067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tags in the dataset\n",
    "len(UD_TAGS.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfa4746",
   "metadata": {
    "id": "580b8c2c",
    "papermill": {
     "duration": 0.106112,
     "end_time": "2023-03-28T00:05:19.318254",
     "exception": false,
     "start_time": "2023-03-28T00:05:19.212142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Expected output\n",
    "18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49c559d",
   "metadata": {
    "id": "73c8c879",
    "papermill": {
     "duration": 0.168778,
     "end_time": "2023-03-28T00:05:19.594088",
     "exception": false,
     "start_time": "2023-03-28T00:05:19.425310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a name='2.1'></a>\n",
    "# Part 2.1: Building the neural network\n",
    "\n",
    "We will make use of the GloVe embeddings and build a bi-directional LSTM. You will be able to tune the hyper parameters of the network and see what works. \n",
    "\n",
    "It involves duplicating the first recurrent layer in the network so that there are now two layers side-by-side, then providing the input sequence as-is as input to the first layer and providing a reversed copy of the input sequence to the second.\n",
    "\n",
    "The idea is to split the state neurons of a regular RNN in a part that is responsible for the positive time direction (forward states) and a part for the negative time direction (backward states)\n",
    "\n",
    "More on it here: https://maxwell.ict.griffith.edu.au/spl/publications/papers/ieeesp97_schuster.pdf\n",
    "\n",
    "All the internal computations/details will be taken care by PyTorch. You will be able to implement many variations of this neural networks with minor changes in code. Expect your neural network definition to be under 10 lines.\n",
    "\n",
    "Your PyTorch model (inherits torch.nn.Module) definition contains defining two functions:\n",
    "    -Init : Which specifies what layers to initialize.\n",
    "    -Forward: Which defines the order of computations in these layers. <br>\n",
    "**Note** - We will not grade based on accuracy, We grade if your model converges. You can follow your order of code, if you think the comments are not helping.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba3dedd",
   "metadata": {
    "id": "15db110f",
    "papermill": {
     "duration": 0.107363,
     "end_time": "2023-03-28T00:05:19.807891",
     "exception": false,
     "start_time": "2023-03-28T00:05:19.700528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Part 2.1.2 Building LSTM network - 20 Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83263d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:05:20.024731Z",
     "iopub.status.busy": "2023-03-28T00:05:20.024360Z",
     "iopub.status.idle": "2023-03-28T00:05:20.032626Z",
     "shell.execute_reply": "2023-03-28T00:05:20.031520Z"
    },
    "id": "934c9eb8",
    "papermill": {
     "duration": 0.119683,
     "end_time": "2023-03-28T00:05:20.034737",
     "exception": false,
     "start_time": "2023-03-28T00:05:19.915054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMPOSTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout, \n",
    "                 pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Define an embedding layer that converts the words to embeddings based on GloVe.\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        # Define a bi-directional LSTM layer with the hyperparameters. \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)       \n",
    "        \n",
    "        # Define a dropout layer that helps in regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Define a Linear layer which can associate lstm output to the final output \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, text):\n",
    "        # pass text through embedding layer\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        # pass embeddings into LSTM\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        # pass the LSTM output to dropout and fully connected linear layer\n",
    "        embedded_dropout = self.dropout(outputs)\n",
    "        predictions = self.fc(embedded_dropout)\n",
    "        \n",
    "        # we use our outputs to make a prediction of what the tag should be\n",
    "        # predictions = [sent len, batch size, output dim]\n",
    "      \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d10a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:05:20.249003Z",
     "iopub.status.busy": "2023-03-28T00:05:20.248625Z",
     "iopub.status.idle": "2023-03-28T00:05:20.281449Z",
     "shell.execute_reply": "2023-03-28T00:05:20.280524Z"
    },
    "id": "e934c279",
    "papermill": {
     "duration": 0.142798,
     "end_time": "2023-03-28T00:05:20.283747",
     "exception": false,
     "start_time": "2023-03-28T00:05:20.140949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tweak the Nones\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(UD_TAGS.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = LSTMPOSTagger(INPUT_DIM, \n",
    "                        EMBEDDING_DIM, \n",
    "                        HIDDEN_DIM, \n",
    "                        OUTPUT_DIM, \n",
    "                        N_LAYERS, \n",
    "                        BIDIRECTIONAL, \n",
    "                        DROPOUT, \n",
    "                        PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876d40c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:05:20.500520Z",
     "iopub.status.busy": "2023-03-28T00:05:20.498930Z",
     "iopub.status.idle": "2023-03-28T00:05:20.566252Z",
     "shell.execute_reply": "2023-03-28T00:05:20.565173Z"
    },
    "id": "be98840c",
    "papermill": {
     "duration": 0.178487,
     "end_time": "2023-03-28T00:05:20.568829",
     "exception": false,
     "start_time": "2023-03-28T00:05:20.390342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initializing model weights for better convergence\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, std=0.1)\n",
    "model.apply(init_weights)\n",
    "\n",
    "# initializing model embeddings with glove word vectors\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "# making the padding embeddings as all zero, as we don't want to learn paddings.\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d33f7dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:05:20.787202Z",
     "iopub.status.busy": "2023-03-28T00:05:20.786298Z",
     "iopub.status.idle": "2023-03-28T00:05:20.792442Z",
     "shell.execute_reply": "2023-03-28T00:05:20.791473Z"
    },
    "id": "8d091aa1",
    "papermill": {
     "duration": 0.118235,
     "end_time": "2023-03-28T00:05:20.794720",
     "exception": false,
     "start_time": "2023-03-28T00:05:20.676485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If your PC doesn't have enough CPU Ram or Video memory, try decreasing the batch_size\n",
    "BATCH_SIZE = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60de4fc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:05:21.011556Z",
     "iopub.status.busy": "2023-03-28T00:05:21.011190Z",
     "iopub.status.idle": "2023-03-28T00:05:21.016443Z",
     "shell.execute_reply": "2023-03-28T00:05:21.015456Z"
    },
    "id": "da241904",
    "papermill": {
     "duration": 0.116401,
     "end_time": "2023-03-28T00:05:21.018499",
     "exception": false,
     "start_time": "2023-03-28T00:05:20.902098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BucketIterator allows for data to be split into buckets of equal size,\n",
    "# any remaining space is filled with pad token\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)\n",
    "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a3ab38",
   "metadata": {
    "id": "51d828c6",
    "papermill": {
     "duration": 0.106639,
     "end_time": "2023-03-28T00:05:21.232028",
     "exception": false,
     "start_time": "2023-03-28T00:05:21.125389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Optimizer and Loss Function\n",
    "Optimizers are algorithms or methods used to change the attributes of the neural network such as weights and learning rate to reduce the losses. Optimizers are used to solve optimization problems by minimizing the function.\n",
    "- PyTorch provides many Optimizer Algorithms, feel free to try them and the one that works best for you. \n",
    "- Link - https://pytorch.org/docs/stable/optim.html\n",
    "- We will be using CrossEntropyLoss as predicting a word tag is a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d99df47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:05:21.447688Z",
     "iopub.status.busy": "2023-03-28T00:05:21.446669Z",
     "iopub.status.idle": "2023-03-28T00:05:21.452550Z",
     "shell.execute_reply": "2023-03-28T00:05:21.451613Z"
    },
    "id": "df62b86b",
    "papermill": {
     "duration": 0.115882,
     "end_time": "2023-03-28T00:05:21.454635",
     "exception": false,
     "start_time": "2023-03-28T00:05:21.338753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optimizer to train the model\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# ignoring the padding in our loss calculation\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa2ec29a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:05:21.668844Z",
     "iopub.status.busy": "2023-03-28T00:05:21.668466Z",
     "iopub.status.idle": "2023-03-28T00:05:21.672796Z",
     "shell.execute_reply": "2023-03-28T00:05:21.671765Z"
    },
    "id": "GpesRX5p1THb",
    "outputId": "0c9a77e5-3243-4187-f32c-b14bc55d141d",
    "papermill": {
     "duration": 0.114425,
     "end_time": "2023-03-28T00:05:21.675101",
     "exception": false,
     "start_time": "2023-03-28T00:05:21.560676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import locale\n",
    "#locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c70d8e69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:05:21.889908Z",
     "iopub.status.busy": "2023-03-28T00:05:21.889529Z",
     "iopub.status.idle": "2023-03-28T00:05:25.688175Z",
     "shell.execute_reply": "2023-03-28T00:05:25.687091Z"
    },
    "id": "ed8f23af",
    "outputId": "085e88ab-b05e-4a7c-d2dc-445f3f62ef50",
    "papermill": {
     "duration": 3.907606,
     "end_time": "2023-03-28T00:05:25.690654",
     "exception": false,
     "start_time": "2023-03-28T00:05:21.783048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# use gpu if available, These lines move your model to gpu from cpu if available\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# If this line prints cuda, your machine is equipped with a Nvidia GPU and PyTorch is utilizing the GPU\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "391f04c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:05:25.905552Z",
     "iopub.status.busy": "2023-03-28T00:05:25.905187Z",
     "iopub.status.idle": "2023-03-28T00:05:25.911788Z",
     "shell.execute_reply": "2023-03-28T00:05:25.910743Z"
    },
    "id": "8db84a91",
    "papermill": {
     "duration": 0.115938,
     "end_time": "2023-03-28T00:05:25.914042",
     "exception": false,
     "start_time": "2023-03-28T00:05:25.798104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# method to check for accurcy of the model ignoring the pad index\n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = (y != TAG_PAD_IDX).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / y[non_pad_elements].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b733d3",
   "metadata": {
    "id": "85894831",
    "papermill": {
     "duration": 0.105421,
     "end_time": "2023-03-28T00:05:26.167820",
     "exception": false,
     "start_time": "2023-03-28T00:05:26.062399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Part 2.1.2 - Training and Testing LSTM - 20 Points\n",
    "- Decide your epochs to train based on loss and accuracy\n",
    "- Fill single line PyTorch commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec7b5ee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:05:26.382316Z",
     "iopub.status.busy": "2023-03-28T00:05:26.381963Z",
     "iopub.status.idle": "2023-03-28T00:07:00.368276Z",
     "shell.execute_reply": "2023-03-28T00:07:00.367104Z"
    },
    "id": "ef894a29",
    "outputId": "01bffa05-4f6c-41cc-f9e8-a0baf3b52d99",
    "papermill": {
     "duration": 94.096229,
     "end_time": "2023-03-28T00:07:00.370556",
     "exception": false,
     "start_time": "2023-03-28T00:05:26.274327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:05<01:36,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 1.448 | [Train Acc] : 53.91%\n",
      "\n",
      "\t [Val Loss] : 0.602 | [Val Acc] : 80.95%\n",
      "\n",
      "Epoch: 02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:09<01:27,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.667 | [Train Acc] : 78.42%\n",
      "\n",
      "\t [Val Loss] : 0.443 | [Val Acc] : 85.16%\n",
      "\n",
      "Epoch: 03\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:14<01:20,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.508 | [Train Acc] : 83.58%\n",
      "\n",
      "\t [Val Loss] : 0.379 | [Val Acc] : 87.63%\n",
      "\n",
      "Epoch: 04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:18<01:15,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.423 | [Train Acc] : 86.32%\n",
      "\n",
      "\t [Val Loss] : 0.337 | [Val Acc] : 88.70%\n",
      "\n",
      "Epoch: 05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:23<01:10,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.368 | [Train Acc] : 88.07%\n",
      "\n",
      "\t [Val Loss] : 0.310 | [Val Acc] : 89.40%\n",
      "\n",
      "Epoch: 06\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:28<01:05,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.329 | [Train Acc] : 89.37%\n",
      "\n",
      "\t [Val Loss] : 0.299 | [Val Acc] : 89.96%\n",
      "\n",
      "Epoch: 07\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:33<01:00,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.300 | [Train Acc] : 90.26%\n",
      "\n",
      "\t [Val Loss] : 0.289 | [Val Acc] : 90.32%\n",
      "\n",
      "Epoch: 08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:37<00:56,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.280 | [Train Acc] : 90.95%\n",
      "\n",
      "\t [Val Loss] : 0.285 | [Val Acc] : 90.58%\n",
      "\n",
      "Epoch: 09\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:42<00:51,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.259 | [Train Acc] : 91.53%\n",
      "\n",
      "\t [Val Loss] : 0.273 | [Val Acc] : 90.88%\n",
      "\n",
      "Epoch: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:47<00:46,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.244 | [Train Acc] : 92.03%\n",
      "\n",
      "\t [Val Loss] : 0.267 | [Val Acc] : 90.97%\n",
      "\n",
      "Epoch: 11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:51<00:42,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.233 | [Train Acc] : 92.37%\n",
      "\n",
      "\t [Val Loss] : 0.258 | [Val Acc] : 91.84%\n",
      "\n",
      "Epoch: 12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:56<00:37,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.221 | [Train Acc] : 92.82%\n",
      "\n",
      "\t [Val Loss] : 0.262 | [Val Acc] : 91.36%\n",
      "\n",
      "Epoch: 13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [01:01<00:32,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.211 | [Train Acc] : 93.19%\n",
      "\n",
      "\t [Val Loss] : 0.262 | [Val Acc] : 91.61%\n",
      "\n",
      "Epoch: 14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [01:05<00:28,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.202 | [Train Acc] : 93.43%\n",
      "\n",
      "\t [Val Loss] : 0.260 | [Val Acc] : 91.28%\n",
      "\n",
      "Epoch: 15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [01:10<00:23,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.193 | [Train Acc] : 93.72%\n",
      "\n",
      "\t [Val Loss] : 0.254 | [Val Acc] : 91.84%\n",
      "\n",
      "Epoch: 16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [01:15<00:18,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.187 | [Train Acc] : 93.95%\n",
      "\n",
      "\t [Val Loss] : 0.254 | [Val Acc] : 91.84%\n",
      "\n",
      "Epoch: 17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [01:19<00:14,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.179 | [Train Acc] : 94.13%\n",
      "\n",
      "\t [Val Loss] : 0.250 | [Val Acc] : 92.15%\n",
      "\n",
      "Epoch: 18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [01:24<00:09,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.173 | [Train Acc] : 94.34%\n",
      "\n",
      "\t [Val Loss] : 0.247 | [Val Acc] : 92.26%\n",
      "\n",
      "Epoch: 19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [01:29<00:04,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.168 | [Train Acc] : 94.49%\n",
      "\n",
      "\t [Val Loss] : 0.250 | [Val Acc] : 92.17%\n",
      "\n",
      "Epoch: 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:33<00:00,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Train Loss] : 0.162 | [Train Acc] : 94.65%\n",
      "\n",
      "\t [Val Loss] : 0.251 | [Val Acc] : 92.17%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    model.train()\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    print(f'Epoch: {epoch+1:02}\\n')\n",
    "    for batch in train_iterator:\n",
    "        \n",
    "        # returns a batch of text to train on (sent len, batch size)\n",
    "        text = batch.text\n",
    "        tags = batch.udtags\n",
    "        \n",
    "        # Add a command that makes the optimizer with zero gradients for each iteration \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        # Add a command that feeds the batch to the model\n",
    "        predictions = model(text)\n",
    "\n",
    "        \n",
    "        # predictions = (sent len, batch size, output dim)\n",
    "          # tags = (sent len, batch size)\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        # Add a command that calculates loss\n",
    "        loss = criterion(predictions, tags)\n",
    "\n",
    "        \n",
    "        # Make use of the categorical accuracy and calculate accuracy\n",
    "        acc = categorical_accuracy(predictions, tags)\n",
    "\n",
    "        \n",
    "        # Add a command that calculates gradients\n",
    "        loss.backward()\n",
    "\n",
    "        \n",
    "        # Add a command that updates the weights by taking steps \n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate loss and accuracy for the epoch\n",
    "        train_epoch_loss += loss.item()\n",
    "        train_epoch_acc += acc.item()\n",
    "\n",
    "    train_epoch_loss /= len(train_iterator)\n",
    "    train_epoch_acc /= len(train_iterator)\n",
    "                  \n",
    "     # Calculate loss\n",
    "    print(f'\\t [Train Loss] : {train_epoch_loss:.3f} | [Train Acc] : {train_epoch_acc*100:.2f}%\\n')\n",
    "    \n",
    "  \n",
    "    val_epoch_loss = 0\n",
    "    val_epoch_acc = 0 \n",
    "\n",
    "    # Add a command that moves the model to validation mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in valid_iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.udtags\n",
    "        \n",
    "            # Add the same command that feeds the batch to the model\n",
    "            predictions = model(text)\n",
    "            \n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "            \n",
    "            # Add the same command that calculates loss\n",
    "            val_loss = criterion(predictions, tags)\n",
    "\n",
    "            # Make use of the categorical accuracy function and calculate accuracy\n",
    "            val_acc = categorical_accuracy(predictions, tags)\n",
    "\n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_acc += val_acc.item()\n",
    "\n",
    "  # Calculate validation loss\n",
    "    \n",
    "    val_epoch_loss /= len(valid_iterator)\n",
    "    val_epoch_acc /= len(valid_iterator)\n",
    "\n",
    "    print(f'\\t [Val Loss] : {val_loss:.3f} | [Val Acc] : {val_acc*100:.2f}%\\n')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc1cfa83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:07:00.588999Z",
     "iopub.status.busy": "2023-03-28T00:07:00.588618Z",
     "iopub.status.idle": "2023-03-28T00:07:00.696430Z",
     "shell.execute_reply": "2023-03-28T00:07:00.695237Z"
    },
    "id": "33858a16",
    "papermill": {
     "duration": 0.220225,
     "end_time": "2023-03-28T00:07:00.699301",
     "exception": false,
     "start_time": "2023-03-28T00:07:00.479076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 89.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing the accuracy on test set\n",
    "test_acc=0\n",
    "model.eval()\n",
    "\n",
    "# Computes without the gradients. Use this while testing your model.\n",
    "# As we do not intend to learn from the data\n",
    "with torch.no_grad():\n",
    "    for batch in test_iterator:\n",
    "      \n",
    "      text = batch.text\n",
    "      tags = batch.udtags\n",
    "\n",
    "    # Add the same command that feeds the batch to the model\n",
    "      predictions = model(text)\n",
    "\n",
    "      predictions = predictions.view(-1, predictions.shape[-1])\n",
    "      tags = tags.view(-1)\n",
    "\n",
    "    # Make use of the categorical accuracy function and calculate accuracy\n",
    "      test_acc += categorical_accuracy(predictions, tags)\n",
    "    \n",
    "# Calculate Accuracy\n",
    "\n",
    "final_acc = test_acc / len(test_iterator)\n",
    "print(f'Test Acc: {final_acc*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a3cdf3",
   "metadata": {
    "id": "173e7745",
    "papermill": {
     "duration": 0.109008,
     "end_time": "2023-03-28T00:07:00.917778",
     "exception": false,
     "start_time": "2023-03-28T00:07:00.808770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***Note***: You are using a different dataset compared to part 1 and 2. This part of the assignment is designed/aimed to help develop basic understanding of Neural Networks. Although we expect an accuracy of above 85%, we do not grade based on the accuracy output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec52ba25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:07:01.136740Z",
     "iopub.status.busy": "2023-03-28T00:07:01.136377Z",
     "iopub.status.idle": "2023-03-28T00:07:01.142738Z",
     "shell.execute_reply": "2023-03-28T00:07:01.141751Z"
    },
    "id": "ea018747",
    "papermill": {
     "duration": 0.118787,
     "end_time": "2023-03-28T00:07:01.144906",
     "exception": false,
     "start_time": "2023-03-28T00:07:01.026119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try different inputs to these function.\n",
    "def test_lstm(test_sentence):\n",
    "    x= test_sentence.unsqueeze(-1).to(device)\n",
    "    pred = model(x)\n",
    "    pred = pred.argmax(-1)\n",
    "    pred_tags = [UD_TAGS.vocab.itos[t.item()] for t in pred]\n",
    "    true_tags = [UD_TAGS.vocab.itos[t.item()] for t in test_labels]\n",
    "    tokenized_sentence = [TEXT.vocab.itos[t.item()] for t in test_sentence]\n",
    "    return tokenized_sentence, true_tags,pred_tags    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d34df545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:07:01.362534Z",
     "iopub.status.busy": "2023-03-28T00:07:01.362165Z",
     "iopub.status.idle": "2023-03-28T00:07:01.386038Z",
     "shell.execute_reply": "2023-03-28T00:07:01.384418Z"
    },
    "id": "c8c7a491",
    "papermill": {
     "duration": 0.135198,
     "end_time": "2023-03-28T00:07:01.388162",
     "exception": false,
     "start_time": "2023-03-28T00:07:01.252964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', 'stay', 'important', 'the', '<unk>', 'i', 'did', '<unk>', 'the', 'here', 'we', 'as', 'i', 'on', '<unk>', 'it', 'it', 'just', '\"', 'the', 'the', '\"', 'if', 'the', 'any', 'in', 'in', 'over', 'it']\n",
      "True tags ['PUNCT', 'VERB', 'ADJ', 'DET', 'ADV', 'PRON', 'AUX', 'PROPN', 'DET', 'ADV', 'PRON', 'SCONJ', 'PRON', 'ADP', 'PROPN', 'PRON', 'PRON', 'ADV', 'PUNCT', 'DET', 'DET', 'PUNCT', 'SCONJ', 'DET', 'DET', 'ADP', 'ADP', 'ADV', 'PRON']\n",
      "Predicted Tags ['PUNCT', 'VERB', 'ADJ', 'DET', 'NOUN', 'PRON', 'AUX', 'VERB', 'DET', 'ADV', 'PRON', 'SCONJ', 'PRON', 'SCONJ', 'VERB', 'PRON', 'PRON', 'ADV', 'PUNCT', 'DET', 'DET', 'PUNCT', 'SCONJ', 'DET', 'DET', 'ADP', 'ADV', 'ADP', 'PRON']\n"
     ]
    }
   ],
   "source": [
    "test_sentence = text[0]\n",
    "test_labels = tags[0:len(test_sentence)]\n",
    "print(test_lstm(test_sentence)[0])\n",
    "print(\"True tags\", test_lstm(test_sentence)[1])\n",
    "print(\"Predicted Tags\",test_lstm(test_sentence)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4ff61fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T00:07:01.607550Z",
     "iopub.status.busy": "2023-03-28T00:07:01.606892Z",
     "iopub.status.idle": "2023-03-28T00:07:01.655692Z",
     "shell.execute_reply": "2023-03-28T00:07:01.654180Z"
    },
    "id": "c63cb3d5",
    "papermill": {
     "duration": 0.16123,
     "end_time": "2023-03-28T00:07:01.658524",
     "exception": false,
     "start_time": "2023-03-28T00:07:01.497294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save your model if it performs well. This saves all the trained weights,\n",
    "# so that you don't have to train again in your codewalk\n",
    "torch.save(model.state_dict(), \"./LSTMPOSTAG.pth\")\n",
    "\n",
    "# loading?l\n",
    "# model.load_state_dict(torch.load(\"./LSTMPOSTAG.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf90cd",
   "metadata": {
    "id": "43aee2ed",
    "papermill": {
     "duration": 0.106729,
     "end_time": "2023-03-28T00:07:01.880606",
     "exception": false,
     "start_time": "2023-03-28T00:07:01.773877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Theory Questions: 10 Points\n",
    "*** Q1. Give some real word examples where POS tagging is used   ***<br>\n",
    "*** Q2. What are the hidden variables in HMM in this assignment? Why are they called hidden? *** <br>\n",
    "*** Q3. How Viterbi Algorithm provides more efficient estimation compared to brute force calculation of all tag combinations? *** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4bf0c",
   "metadata": {
    "papermill": {
     "duration": 0.10811,
     "end_time": "2023-03-28T00:07:02.096459",
     "exception": false,
     "start_time": "2023-03-28T00:07:01.988349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Q1\n",
    "1. Text-to-speech (TTS) systems: POS tagging is used to determine the correct pronunciation and intonation of words in a text-to-speech system. By identifying the part of speech of each word, the TTS system can determine the correct stress and emphasis to use when speaking the word.\n",
    "\n",
    "2. Information retrieval: POS tagging can be used to improve search results in information retrieval systems. By identifying the part of speech of each word in a query, the system can better understand the user's intent and retrieve more relevant documents.\n",
    "\n",
    "3. Sentiment analysis: POS tagging is used to identify the parts of speech that are most associated with positive or negative sentiment in a text. By analyzing the frequency and distribution of these parts of speech, sentiment analysis models can classify the overall sentiment of a piece of text.\n",
    "\n",
    "4. Machine translation: POS tagging is used to improve the accuracy of machine translation systems. By identifying the part of speech of each word in the source language, the system can better understand the structure and meaning of the sentence and generate more accurate translations.\n",
    "\n",
    "5. Named entity recognition: POS tagging is used to identify named entities such as people, places, and organizations in a text. By identifying the part of speech of each word in a sentence, named entity recognition models can more accurately identify and classify these entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999110e",
   "metadata": {
    "papermill": {
     "duration": 0.107202,
     "end_time": "2023-03-28T00:07:02.312727",
     "exception": false,
     "start_time": "2023-03-28T00:07:02.205525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Q2\n",
    "HMMs (Hidden Markov Models) are a type of probabilistic graphical model that can predict a series of unknown (hidden) variables given a set of observed variables. The terms \"states\" and \"observations\" are used interchangeably to refer to the hidden and observable states, respectively.\n",
    "\n",
    "Transition data – the likelihood of shifting to a new state based on the current state.\n",
    "\n",
    "Emission data – the likelihood of moving from a hidden state to an observed state.\n",
    "\n",
    "Initial state information — the initial probability of transitioning to a hidden state. This might also be referred to as the likelihood previous to the event. The data or emission matrix is conditioned on the hidden state, which is C(ti), which is the number of times tags appeared in the training data (stored in the tag counts dictionary)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b238aa9b",
   "metadata": {
    "papermill": {
     "duration": 0.153771,
     "end_time": "2023-03-28T00:07:02.575407",
     "exception": false,
     "start_time": "2023-03-28T00:07:02.421636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Q3\n",
    "The Viterbi algorithm provides a more efficient estimation compared to the brute-force calculation of all tag combinations by breaking down the problem into smaller subproblems and avoiding redundant calculations. Instead of calculating all possible tag sequences, the algorithm recursively computes the maximum probability of a sequence of hidden states that ends in a given state at each position in the sequence. It keeps track of the maximum probability of a partial sequence of hidden states up to each position and the most likely tag that led to that maximum probability. By using the results of previous subproblems to efficiently compute the current subproblem, the algorithm avoids redundant calculations and significantly reduces the computation time required to estimate the most likely sequence of hidden states. This makes it possible to find the most likely sequence of hidden states even for long sequences and large state spaces in linear time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 413.189382,
   "end_time": "2023-03-28T00:07:06.126728",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-28T00:00:12.937346",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
